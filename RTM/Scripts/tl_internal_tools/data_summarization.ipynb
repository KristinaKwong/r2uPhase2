{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "import inro.modeller as _m\n",
    "import inro.emme.desktop as _d\n",
    "import traceback as _traceback\n",
    "\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "import csv as csv\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "eb = _m.Modeller().emmebank\n",
    "util = _m.Modeller().tool(\"translink.util\")\n",
    "data_export = _m.Modeller().tool(\"translink.RTM3.stage4.dataexport\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "dt = _d.app.connect()\n",
    "de = dt.data_explorer()\n",
    "db = de.active_database()\n",
    "ebs = de.databases()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ],
    "collapsed": false,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "am_scenid = eb.scenario(int(eb.matrix(\"msAmScen\").data))\n",
    "md_scenid = eb.scenario(int(eb.matrix(\"msMdScen\").data))\n",
    "pm_scenid = eb.scenario(int(eb.matrix(\"msPmScen\").data))\n",
    "\n",
    "# following needs to be the scenario object\n",
    "scens = [am_scenid,md_scenid,pm_scenid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "show_input": true
   },
   "source": [
    "## Define the update function - this needs to be moved to the model at some point (done - not needed any more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "def autoStats(eb):\n",
    "    util = _m.Modeller().tool(\"translink.util\")\n",
    "    aonDist = util.get_matrix_numpy(eb, \"mfdistAON\").flatten()\n",
    "    df = util.get_ijensem_df(eb, 'gy','gy')\n",
    "\n",
    "    df['amSovDemand1'] = util.get_matrix_numpy(eb, \"mfSOV_drvtrp_VOT_1_Am\").flatten()\n",
    "    df['amSovDemand2'] = util.get_matrix_numpy(eb, \"mfSOV_drvtrp_VOT_2_Am\").flatten()\n",
    "    df['amSovDemand3'] = util.get_matrix_numpy(eb, \"mfSOV_drvtrp_VOT_3_Am\").flatten()\n",
    "    df['amSovDemand4'] = util.get_matrix_numpy(eb, \"mfSOV_drvtrp_VOT_4_Am\").flatten()\n",
    "\n",
    "    df['mdSovDemand1'] = util.get_matrix_numpy(eb, \"mfSOV_drvtrp_VOT_1_Md\").flatten()\n",
    "    df['mdSovDemand2'] = util.get_matrix_numpy(eb, \"mfSOV_drvtrp_VOT_2_Md\").flatten()\n",
    "    df['mdSovDemand3'] = util.get_matrix_numpy(eb, \"mfSOV_drvtrp_VOT_3_Md\").flatten()\n",
    "    df['mdSovDemand4'] = util.get_matrix_numpy(eb, \"mfSOV_drvtrp_VOT_4_Md\").flatten()\n",
    "\n",
    "    df['pmSovDemand1'] = util.get_matrix_numpy(eb, \"mfSOV_drvtrp_VOT_1_Pm\").flatten()\n",
    "    df['pmSovDemand2'] = util.get_matrix_numpy(eb, \"mfSOV_drvtrp_VOT_2_Pm\").flatten()\n",
    "    df['pmSovDemand3'] = util.get_matrix_numpy(eb, \"mfSOV_drvtrp_VOT_3_Pm\").flatten()\n",
    "    df['pmSovDemand4'] = util.get_matrix_numpy(eb, \"mfSOV_drvtrp_VOT_4_Pm\").flatten()\n",
    "\n",
    "\n",
    "    df['amHovDemand1'] = util.get_matrix_numpy(eb, \"mfHOV_drvtrp_VOT_1_Am\").flatten()\n",
    "    df['amHovDemand2'] = util.get_matrix_numpy(eb, \"mfHOV_drvtrp_VOT_2_Am\").flatten()\n",
    "    df['amHovDemand3'] = util.get_matrix_numpy(eb, \"mfHOV_drvtrp_VOT_3_Am\").flatten()\n",
    "    df['amHovDemand4'] = util.get_matrix_numpy(eb, \"mfHOV_drvtrp_VOT_4_Am\").flatten()\n",
    "\n",
    "    df['mdHovDemand1'] = util.get_matrix_numpy(eb, \"mfHOV_drvtrp_VOT_1_Md\").flatten()\n",
    "    df['mdHovDemand2'] = util.get_matrix_numpy(eb, \"mfHOV_drvtrp_VOT_2_Md\").flatten()\n",
    "    df['mdHovDemand3'] = util.get_matrix_numpy(eb, \"mfHOV_drvtrp_VOT_3_Md\").flatten()\n",
    "    df['mdHovDemand4'] = util.get_matrix_numpy(eb, \"mfHOV_drvtrp_VOT_4_Md\").flatten()\n",
    "\n",
    "    df['pmHovDemand1'] = util.get_matrix_numpy(eb, \"mfHOV_drvtrp_VOT_1_Pm\").flatten()\n",
    "    df['pmHovDemand2'] = util.get_matrix_numpy(eb, \"mfHOV_drvtrp_VOT_2_Pm\").flatten()\n",
    "    df['pmHovDemand3'] = util.get_matrix_numpy(eb, \"mfHOV_drvtrp_VOT_3_Pm\").flatten()\n",
    "    df['pmHovDemand4'] = util.get_matrix_numpy(eb, \"mfHOV_drvtrp_VOT_4_Pm\").flatten()\n",
    "    \n",
    "    df['amLGVDemand1'] = util.get_matrix_numpy(eb, \"mfLGVAM\").flatten()\n",
    "    df['amHGVDemand1'] = util.get_matrix_numpy(eb, \"mfHGVAM\").flatten()\n",
    "    df['mdLGVDemand1'] = util.get_matrix_numpy(eb, \"mfLGVMD\").flatten()\n",
    "    df['mdHGVDemand1'] = util.get_matrix_numpy(eb, \"mfHGVMD\").flatten()\n",
    "    df['pmLGVDemand1'] = util.get_matrix_numpy(eb, \"mfLGVPM\").flatten()\n",
    "    df['pmHGVDemand1'] = util.get_matrix_numpy(eb, \"mfHGVPM\").flatten()\n",
    "\n",
    "    # create copy of trips and multiply by distance to get simple vkt\n",
    "    df2 = df.drop(['gy_i','gy_j'], 1).mul(aonDist, axis = 0)\n",
    "    df2.rename(columns= lambda x: re.sub('Demand', 'Vkt', x), inplace=True)\n",
    "    # need to bring back ij refs for group by\n",
    "    df2 = pd.concat([util.get_ijensem_df(eb, 'gy','gy'),df2], axis=1)\n",
    "    df2 = pd.melt(df2, id_vars = ['gy_i','gy_j'], var_name = 'timeModeVot', value_name='vkt')\n",
    "    df2Gy =  df2.groupby(['gy_i','gy_j','timeModeVot'])\n",
    "    df2Gy = df2Gy.sum().reset_index()\n",
    "\n",
    "    df3 = pd.melt(df, id_vars = ['gy_i','gy_j'], var_name = 'timeModeVot', value_name = 'trips')\n",
    "    dfGy = df3.groupby(['gy_i','gy_j','timeModeVot'])\n",
    "    dfGy = dfGy.sum().reset_index()\n",
    "\n",
    "    # extract toll data\n",
    "    dfToll = util.get_ijensem_df(eb, 'gy','gy')\n",
    "    dfToll['amSovToll1'] = df['amSovDemand1'].multiply(util.get_matrix_numpy(eb, \"mfAmSovTollVOT1\").flatten(), axis = 0)\n",
    "    dfToll['amSovToll2'] = df['amSovDemand2'].multiply(util.get_matrix_numpy(eb, \"mfAmSovTollVOT2\").flatten(), axis = 0)\n",
    "    dfToll['amSovToll3'] = df['amSovDemand3'].multiply(util.get_matrix_numpy(eb, \"mfAmSovTollVOT3\").flatten(), axis = 0)\n",
    "    dfToll['amSovToll4'] = df['amSovDemand4'].multiply(util.get_matrix_numpy(eb, \"mfAmSovTollVOT4\").flatten(), axis = 0)\n",
    "    dfToll['mdSovToll1'] = df['mdSovDemand1'].multiply(util.get_matrix_numpy(eb, \"mfMdSovTollVOT1\").flatten(), axis = 0)\n",
    "    dfToll['mdSovToll2'] = df['mdSovDemand2'].multiply(util.get_matrix_numpy(eb, \"mfMdSovTollVOT2\").flatten(), axis = 0)\n",
    "    dfToll['mdSovToll3'] = df['mdSovDemand3'].multiply(util.get_matrix_numpy(eb, \"mfMdSovTollVOT3\").flatten(), axis = 0)\n",
    "    dfToll['mdSovToll4'] = df['mdSovDemand4'].multiply(util.get_matrix_numpy(eb, \"mfMdSovTollVOT4\").flatten(), axis = 0)\n",
    "    dfToll['pmSovToll1'] = df['pmSovDemand1'].multiply(util.get_matrix_numpy(eb, \"mfPmSovTollVOT1\").flatten(), axis = 0)\n",
    "    dfToll['pmSovToll2'] = df['pmSovDemand2'].multiply(util.get_matrix_numpy(eb, \"mfPmSovTollVOT2\").flatten(), axis = 0)\n",
    "    dfToll['pmSovToll3'] = df['pmSovDemand3'].multiply(util.get_matrix_numpy(eb, \"mfPmSovTollVOT3\").flatten(), axis = 0)\n",
    "    dfToll['pmSovToll4'] = df['pmSovDemand4'].multiply(util.get_matrix_numpy(eb, \"mfPmSovTollVOT4\").flatten(), axis = 0)\n",
    "    dfToll['amHovToll1'] = df['amHovDemand1'].multiply(util.get_matrix_numpy(eb, \"mfAmHovTollVOT1\").flatten(), axis = 0)\n",
    "    dfToll['amHovToll2'] = df['amHovDemand2'].multiply(util.get_matrix_numpy(eb, \"mfAmHovTollVOT2\").flatten(), axis = 0)\n",
    "    dfToll['amHovToll3'] = df['amHovDemand3'].multiply(util.get_matrix_numpy(eb, \"mfAmHovTollVOT3\").flatten(), axis = 0)\n",
    "    dfToll['amHovToll4'] = df['amHovDemand4'].multiply(util.get_matrix_numpy(eb, \"mfAmHovTollVOT4\").flatten(), axis = 0)\n",
    "    dfToll['mdHovToll1'] = df['mdHovDemand1'].multiply(util.get_matrix_numpy(eb, \"mfMdHovTollVOT1\").flatten(), axis = 0)\n",
    "    dfToll['mdHovToll2'] = df['mdHovDemand2'].multiply(util.get_matrix_numpy(eb, \"mfMdHovTollVOT2\").flatten(), axis = 0)\n",
    "    dfToll['mdHovToll3'] = df['mdHovDemand3'].multiply(util.get_matrix_numpy(eb, \"mfMdHovTollVOT3\").flatten(), axis = 0)\n",
    "    dfToll['mdHovToll4'] = df['mdHovDemand4'].multiply(util.get_matrix_numpy(eb, \"mfMdHovTollVOT4\").flatten(), axis = 0)\n",
    "    dfToll['pmHovToll1'] = df['pmHovDemand1'].multiply(util.get_matrix_numpy(eb, \"mfPmHovTollVOT1\").flatten(), axis = 0)\n",
    "    dfToll['pmHovToll2'] = df['pmHovDemand2'].multiply(util.get_matrix_numpy(eb, \"mfPmHovTollVOT2\").flatten(), axis = 0)\n",
    "    dfToll['pmHovToll3'] = df['pmHovDemand3'].multiply(util.get_matrix_numpy(eb, \"mfPmHovTollVOT3\").flatten(), axis = 0)\n",
    "    dfToll['pmHovToll4'] = df['pmHovDemand4'].multiply(util.get_matrix_numpy(eb, \"mfPmHovTollVOT4\").flatten(), axis = 0)\n",
    "    dfToll['amLGVToll1'] = df['amLGVDemand1'].multiply(util.get_matrix_numpy(eb, \"mfAmLgvToll\").flatten(), axis = 0)\n",
    "    dfToll['amHGVToll1'] = df['amHGVDemand1'].multiply(util.get_matrix_numpy(eb, \"mfAmHgvToll\").flatten(), axis = 0)\n",
    "    dfToll['mdLGVToll1'] = df['mdLGVDemand1'].multiply(util.get_matrix_numpy(eb, \"mfMdLgvToll\").flatten(), axis = 0)\n",
    "    dfToll['mdHGVToll1'] = df['mdHGVDemand1'].multiply(util.get_matrix_numpy(eb, \"mfMdHgvToll\").flatten(), axis = 0)\n",
    "    dfToll['pmLGVToll1'] = df['pmLGVDemand1'].multiply(util.get_matrix_numpy(eb, \"mfPmLgvToll\").flatten(), axis = 0)\n",
    "    dfToll['pmHGVToll1'] = df['pmHGVDemand1'].multiply(util.get_matrix_numpy(eb, \"mfPmHgvToll\").flatten(), axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "    dfToll = pd.melt(dfToll, id_vars = ['gy_i','gy_j'], var_name = 'timeModeVot', value_name = 'tolls')\n",
    "    dfTollGy = dfToll.groupby(['gy_i','gy_j','timeModeVot'])\n",
    "    dfTollGy = dfTollGy.sum().reset_index()\n",
    "\n",
    "\n",
    "    # create categorical fields from original colnames\n",
    "    dfTimeModeVot = dfGy['timeModeVot'].str.extract(r'(?P<peak>[a|m|p]{1}[m|d])(?P<mode>Sov|Hov|LGV|HGV)Demand(?P<votclass>\\d)')\n",
    "    dfTimeModeVotT = dfTollGy['timeModeVot'].str.extract(r'(?P<peak>[a|m|p]{1}[m|d])(?P<mode>Sov|Hov|LGV|HGV)Toll(?P<votclass>\\d)')\n",
    "\n",
    "    dfGy = pd.concat([dfGy,dfTimeModeVot], axis=1)\n",
    "    dfGy = dfGy[['gy_i','gy_j','peak','mode','votclass','trips']]\n",
    "\n",
    "    df2Gy = pd.concat([df2Gy,dfTimeModeVot], axis=1)\n",
    "    df2Gy = df2Gy[['gy_i','gy_j','peak','mode','votclass','vkt']]\n",
    "\n",
    "    dfTollGy = pd.concat([dfTollGy,dfTimeModeVotT], axis=1)\n",
    "    dfTollGy = dfTollGy[['gy_i','gy_j','peak','mode','votclass','tolls']]\n",
    "\n",
    "    conn = util.get_db_byname(eb, 'trip_summaries.db')\n",
    "    dfGy.to_sql(name='autoTripsGy', con=conn, flavor='sqlite', index=False, if_exists='replace')\n",
    "    df2Gy.to_sql(name='autoVktGy', con=conn, flavor='sqlite', index=False, if_exists='replace')\n",
    "    dfTollGy.to_sql(name='autoTollGy', con=conn, flavor='sqlite', index=False, if_exists='replace')\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "## Data processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "def ParamsTable(eb):\n",
    "    params = {'autoOpCost' : eb.matrix('msautoOpCost').data,\n",
    "              'lgvOpCost' : eb.matrix('mslgvOpCost').data,\n",
    "              'hgvOpCost' : eb.matrix('mshgvOpCost').data,\n",
    "              'lgvTollFac' : eb.matrix('mslgvTollFac').data,\n",
    "              'hgvTollFac' : eb.matrix('mshgvTollFac').data,\n",
    "              'sovTollFac' : eb.matrix('mssovTollFac').data,\n",
    "              'hovTollFac' : eb.matrix('mshovTollFac').data,\n",
    "             }\n",
    "\n",
    "    params = pd.DataFrame(params, index=[0])   \n",
    "    conn = util.get_db_byname(eb, 'trip_summaries.db')\n",
    "    params.to_sql(name='params', con=conn, flavor='sqlite', index=False, if_exists='replace')\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "def TransitRevenue(eb):\n",
    "    AmFareBus = util.get_matrix_numpy(eb, \"AmBusFare\").flatten()\n",
    "    MdFareBus = util.get_matrix_numpy(eb, \"MdBusFare\").flatten()\n",
    "    PmFareBus = util.get_matrix_numpy(eb, \"PmBusFare\").flatten()\n",
    "    AmFareRail = util.get_matrix_numpy(eb, \"AmRailFare\").flatten()\n",
    "    MdFareRail = util.get_matrix_numpy(eb, \"MdRailFare\").flatten()\n",
    "    PmFareRail = util.get_matrix_numpy(eb, \"PmRailFare\").flatten()\n",
    "    AmFareWce = util.get_matrix_numpy(eb, \"AmWceFare\").flatten()\n",
    "    PmFareWce = util.get_matrix_numpy(eb, \"PmWceFare\").flatten()\n",
    "\n",
    "    AmDemandBus = util.get_matrix_numpy(eb, \"mfbusAm\").flatten()\n",
    "    MdDemandBus = util.get_matrix_numpy(eb, \"mfbusMd\").flatten()\n",
    "    PmDemandBus = util.get_matrix_numpy(eb, \"mfbusPm\").flatten()\n",
    "    AmDemandRail = util.get_matrix_numpy(eb, \"mfrailAm\").flatten()\n",
    "    MdDemandRail = util.get_matrix_numpy(eb, \"mfrailMd\").flatten()\n",
    "    PmDemandRail = util.get_matrix_numpy(eb, \"mfrailPm\").flatten()\n",
    "    AmDemandWce = util.get_matrix_numpy(eb, \"mfWCEAm\").flatten()\n",
    "    PmDemandWce = util.get_matrix_numpy(eb, \"mfWCEPm\").flatten()\n",
    "    \n",
    "    df = pd.DataFrame(index=[0])\n",
    "    \n",
    "    df['AmBusRevenue'] = (AmFareBus * AmDemandBus).sum()\n",
    "    df['MdBusRevenue'] = (MdFareBus * MdDemandBus).sum()\n",
    "    df['PmBusRevenue'] = (PmFareBus * PmDemandBus).sum()\n",
    "    df['AmRailRevenue'] = (AmFareRail * AmDemandRail).sum()\n",
    "    df['MdRailRevenue'] = (MdFareRail * MdDemandRail).sum()\n",
    "    df['PmRailRevenue'] = (PmFareRail * PmDemandRail).sum()\n",
    "    df['AmWceRevenue'] = (AmFareWce * AmDemandWce).sum()\n",
    "    df['PmWceRevenue'] = (PmFareWce * PmDemandWce).sum()\n",
    "    \n",
    "    df = pd.melt(df)\n",
    "    dfTimeMode = df['variable'].str.extract(r'(?P<peak>[A|M|P]{1}[m|d])(?P<mode>Bus|Rail|Wce)(?P<measure>Revenue)')\n",
    "    df = pd.concat([df,dfTimeMode], axis=1)\n",
    "    \n",
    "    df = df[['peak','mode','measure','value']]\n",
    "    \n",
    "    conn = util.get_db_byname(eb, 'trip_summaries.db')\n",
    "    df.to_sql(name='transitRevenue', con=conn, flavor='sqlite', index=False, if_exists='replace')\n",
    "    conn.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "def LosDTime(eb):\n",
    "    conn = util.get_db_byname(eb, 'trip_summaries.db')\n",
    "    df = pd.read_sql(\"SELECT * FROM netResults\", conn)\n",
    "\n",
    "    df['posted_time'] = df['Length'] * 60 / df['posted_speed']\n",
    "    df['losDtime'] = 0.0\n",
    "    df.loc[df.vdf == 1, 'losDtime'] = df['posted_time']\n",
    "    df.loc[df.vdf == 2, 'losDtime'] = df['Auto_Time']\n",
    "    \n",
    "    df.loc[df.vdf==25, 'losDtime'] = 0.25 + df['Length'] * 60 / df['posted_speed'] + 0.85 * (0.85) ** 4\n",
    "    df.loc[df.vdf==35, 'losDtime'] = 0.25 + df['Length'] * 60 / df['posted_speed'] + 0.85 * (0.85) ** 4\n",
    "    df.loc[df.vdf==45, 'losDtime'] = 0.25 + df['Length'] * 60 / df['posted_speed'] + 0.85 * (0.85) ** 4\n",
    "    df.loc[df.vdf==55, 'losDtime'] = 0.25 + df['Length'] * 60 / df['posted_speed'] + 0.85 * (0.85) ** 4\n",
    "    df.loc[df.vdf==65, 'losDtime'] = 0.25 + df['Length'] * 60 / df['posted_speed'] + 0.85 * (0.85) ** 4\n",
    "    df.loc[df.vdf==75, 'losDtime'] = 0.25 + df['Length'] * 60 / df['posted_speed'] + 0.85 * (0.85) ** 4\n",
    "\n",
    "    df.loc[df.vdf==85, 'losDtime'] = df['Length'] * 60 / df['posted_speed'] * (1+ 0.6 * 0.85 * (0.85) ** 5)\n",
    "    df.loc[df.vdf==88, 'losDtime'] = df['Length'] * 60 / (df['posted_speed'] * 1.1)* (1 + 0.6 * 0.43 * (0.85) ** 5.25)\n",
    "\n",
    "    df.loc[df.vdf==3, 'losDtime'] = df['Length'] * 60 / df['posted_speed'] + 0.85 * (0.85) ** 5\n",
    "    df.loc[df.vdf==4, 'losDtime'] = df['Length'] * 60 / df['posted_speed'] + 0.85 * (0.85) ** 5\n",
    "    df.loc[df.vdf==5, 'losDtime'] = df['Length'] * 60 / df['posted_speed'] + 0.85 * (0.85) ** 5\n",
    "    df.loc[df.vdf==6, 'losDtime'] = df['Length'] * 60 / df['posted_speed'] + 0.85 * (0.85) ** 5\n",
    "    df.loc[df.vdf==7, 'losDtime'] = df['Length'] * 60 / df['posted_speed'] + 0.85 * (0.85) ** 5\n",
    "    \n",
    "    df['losDspeed'] = df['Length'] * 60 / df['losDtime']\n",
    " \n",
    "    df.to_sql(name='netResults', con=conn, flavor='sqlite', index=False, if_exists='replace')\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "def CalcParking(eb):\n",
    "    util = _m.Modeller().tool(\"translink.util\")\n",
    "    df = util.get_ijensem_df(eb, 'gy','gy')\n",
    "\n",
    "    ## Get Occupancy\n",
    "    ## Get Cost Skims\n",
    "    # Auto\n",
    "    NoTAZ = len(util.get_matrix_numpy(eb, \"zoneindex\"))\n",
    "\n",
    "    #######################\n",
    "    # HBW\n",
    "    #######################\n",
    "\n",
    "    Occ = float(util.get_matrix_numpy(eb, 'HOVOccHbw'))\n",
    "    Park_cost = util.get_matrix_numpy(eb, 'prk8hr')\n",
    "    Park_cost = np.where(Park_cost>10, 10, Park_cost)\n",
    "    Park_cost = Park_cost.reshape(1, NoTAZ) + np.zeros((NoTAZ, 1))\n",
    "\n",
    "    # cost\n",
    "    sovcst1 = 0.5*Park_cost\n",
    "    sovcst2 = 0.5*Park_cost\n",
    "    sovcst3 = 0.5*Park_cost\n",
    "\n",
    "    hovcst1 = 0.5*Park_cost\n",
    "    hovcst2 = 0.5*Park_cost\n",
    "    hovcst3 = 0.5*Park_cost\n",
    "\n",
    "    # demand\n",
    "    sovdem1 = util.get_matrix_numpy(eb, \"HbWSOVI1PerTrips\")\n",
    "    sovdem2 = util.get_matrix_numpy(eb, \"HbWSOVI2PerTrips\")\n",
    "    sovdem3 = util.get_matrix_numpy(eb, \"HbWSOVI3PerTrips\")\n",
    "\n",
    "    hv2dem1 = util.get_matrix_numpy(eb, \"HbWHV2I1PerTrips\")/2.0\n",
    "    hv2dem2 = util.get_matrix_numpy(eb, \"HbWHV2I2PerTrips\")/2.0\n",
    "    hv2dem3 = util.get_matrix_numpy(eb, \"HbWHV2I3PerTrips\")/2.0\n",
    "\n",
    "    hv3dem1 = util.get_matrix_numpy(eb, \"HbWHV3+I1PerTrips\")/Occ\n",
    "    hv3dem2 = util.get_matrix_numpy(eb, \"HbWHV3+I2PerTrips\")/Occ\n",
    "    hv3dem3 = util.get_matrix_numpy(eb, \"HbWHV3+I3PerTrips\")/Occ\n",
    "\n",
    "    hbwpark = ( sovcst1*sovdem1\n",
    "                        + sovcst2*sovdem2\n",
    "                        + sovcst3*sovdem3\n",
    "                        + hovcst1*hv2dem1\n",
    "                        + hovcst2*hv2dem2\n",
    "                        + hovcst3*hv2dem3\n",
    "                        + hovcst1*hv3dem1\n",
    "                        + hovcst2*hv3dem2\n",
    "                        + hovcst3*hv3dem3 )    \n",
    "\n",
    "    #######################\n",
    "    # HBU\n",
    "    #######################\n",
    "\n",
    "    Occ = float(util.get_matrix_numpy(eb, 'HOVOccHbu'))\n",
    "    Park_cost = util.get_matrix_numpy(eb, 'prk8hr')\n",
    "    Park_cost = np.where(Park_cost>10, 10, Park_cost)\n",
    "    Park_cost = Park_cost.reshape(1, NoTAZ) + np.zeros((NoTAZ, 1))\n",
    "\n",
    "    # cost\n",
    "    sovcst = 0.5*Park_cost\n",
    "    hovcst = 0.5*Park_cost\n",
    "\n",
    "    ## Get demand\n",
    "    sovdem = util.get_matrix_numpy(eb, \"HbUSOVPerTrips\")\n",
    "    hovdem = util.get_matrix_numpy(eb, \"HbUHOVPerTrips\")/Occ\n",
    "\n",
    "    hbupark = ( sovcst*sovdem\n",
    "                    + hovcst*hovdem\n",
    "                    )   \n",
    "\n",
    "    #######################\n",
    "    # HBSchool\n",
    "    #######################\n",
    "\n",
    "    # not clear we would have parking charges for school drop off\n",
    "\n",
    "    #######################\n",
    "    # HBShopping\n",
    "    #######################\n",
    "\n",
    "    Occ = float(util.get_matrix_numpy(eb, 'HOVOccHBshop'))\n",
    "    Park_cost = util.get_matrix_numpy(eb, 'prk2hr')\n",
    "\n",
    "    Park_cost = Park_cost.reshape(1, NoTAZ) + np.zeros((NoTAZ, 1))\n",
    "\n",
    "    sovcst1 = 0.5*Park_cost\n",
    "    sovcst2 = 0.5*Park_cost\n",
    "    sovcst3 = 0.5*Park_cost\n",
    "\n",
    "    hovcst1 = 0.5*Park_cost\n",
    "    hovcst2 = 0.5*Park_cost\n",
    "    hovcst3 = 0.5*Park_cost\n",
    "\n",
    "    ## Get Demands\n",
    "    sovdem1 = util.get_matrix_numpy(eb, \"HbShSOVI1PerTrips\")\n",
    "    sovdem2 = util.get_matrix_numpy(eb, \"HbShSOVI2PerTrips\")\n",
    "    sovdem3 = util.get_matrix_numpy(eb, \"HbShSOVI3PerTrips\")\n",
    "\n",
    "    hovdem1 = util.get_matrix_numpy(eb, \"HbShHOVI1PerTrips\")/Occ\n",
    "    hovdem2 = util.get_matrix_numpy(eb, \"HbShHOVI2PerTrips\")/Occ\n",
    "    hovdem3 = util.get_matrix_numpy(eb, \"HbShHOVI3PerTrips\")/Occ\n",
    "\n",
    "\n",
    "    # Calculate Costs\n",
    "\n",
    "    hbshpark = ( sovcst1*sovdem1\n",
    "                        + sovcst2*sovdem2\n",
    "                        + sovcst3*sovdem3\n",
    "                        + hovcst1*hovdem1\n",
    "                        + hovcst2*hovdem2\n",
    "                        + hovcst3*hovdem3\n",
    "                        )    \n",
    "\n",
    "    #######################\n",
    "    # HBPerBus\n",
    "    #######################\n",
    "\n",
    "    Occ = float(util.get_matrix_numpy(eb, 'HOVOccHbpb'))\n",
    "    Park_cost = util.get_matrix_numpy(eb, 'prk2hr')\n",
    "\n",
    "    Park_cost = Park_cost.reshape(1, NoTAZ) + np.zeros((NoTAZ, 1))\n",
    "\n",
    "    sovcst1 = 0.5*Park_cost\n",
    "    sovcst2 = 0.5*Park_cost\n",
    "    sovcst3 = 0.5*Park_cost\n",
    "\n",
    "    hovcst1 = 0.5*Park_cost\n",
    "    hovcst2 = 0.5*Park_cost\n",
    "    hovcst3 = 0.5*Park_cost\n",
    "\n",
    "    ## Get Demands\n",
    "\n",
    "    sovdem1 = util.get_matrix_numpy(eb, \"HbPbSOVI1PerTrips\")\n",
    "    sovdem2 = util.get_matrix_numpy(eb, \"HbPbSOVI2PerTrips\")\n",
    "    sovdem3 = util.get_matrix_numpy(eb, \"HbPbSOVI3PerTrips\")\n",
    "\n",
    "    hovdem1 = util.get_matrix_numpy(eb, \"HbPbHOVI1PerTrips\")/Occ\n",
    "    hovdem2 = util.get_matrix_numpy(eb, \"HbPbHOVI2PerTrips\")/Occ\n",
    "    hovdem3 = util.get_matrix_numpy(eb, \"HbPbHOVI3PerTrips\")/Occ\n",
    "\n",
    "    # Calculate Costs\n",
    "\n",
    "    hbpbpark = ( sovcst1*sovdem1\n",
    "                        + sovcst2*sovdem2\n",
    "                        + sovcst3*sovdem3\n",
    "                        + hovcst1*hovdem1\n",
    "                        + hovcst2*hovdem2\n",
    "                        + hovcst3*hovdem3\n",
    "                        )\n",
    "\n",
    "    #######################\n",
    "    # HBSocial\n",
    "    #######################\n",
    "\n",
    "    Occ = float(util.get_matrix_numpy(eb, 'HOVOccHBsoc'))\n",
    "    Park_cost = util.get_matrix_numpy(eb, 'prk2hr')\n",
    "\n",
    "    Park_cost = Park_cost.reshape(1, NoTAZ) + np.zeros((NoTAZ, 1))\n",
    "\n",
    "    sovcst1 = 0.5*Park_cost\n",
    "    sovcst2 = 0.5*Park_cost\n",
    "    sovcst3 = 0.5*Park_cost\n",
    "\n",
    "    hovcst1 = 0.5*Park_cost\n",
    "    hovcst2 = 0.5*Park_cost\n",
    "    hovcst3 = 0.5*Park_cost\n",
    "\n",
    "    ## Get Demands\n",
    "\n",
    "    sovdem1 = util.get_matrix_numpy(eb, \"HbSoSOVI1PerTrips\")\n",
    "    sovdem2 = util.get_matrix_numpy(eb, \"HbSoSOVI2PerTrips\")\n",
    "    sovdem3 = util.get_matrix_numpy(eb, \"HbSoSOVI3PerTrips\")\n",
    "\n",
    "    hovdem1 = util.get_matrix_numpy(eb, \"HbSoHOVI1PerTrips\")/Occ\n",
    "    hovdem2 = util.get_matrix_numpy(eb, \"HbSoHOVI2PerTrips\")/Occ\n",
    "    hovdem3 = util.get_matrix_numpy(eb, \"HbSoHOVI3PerTrips\")/Occ\n",
    "\n",
    "    # Calculate Costs\n",
    "\n",
    "    hbsopark = ( sovcst1*sovdem1\n",
    "                        + sovcst2*sovdem2\n",
    "                        + sovcst3*sovdem3\n",
    "                        + hovcst1*hovdem1\n",
    "                        + hovcst2*hovdem2\n",
    "                        + hovcst3*hovdem3\n",
    "                        )\n",
    "\n",
    "    #######################\n",
    "    # HBEsc\n",
    "    #######################\n",
    "\n",
    "    # Not parking when escorting\n",
    "\n",
    "    #######################\n",
    "    # NHBWork\n",
    "    #######################\n",
    "\n",
    "    Occ = float(util.get_matrix_numpy(eb, 'HOVOccNHBw'))\n",
    "    Park_cost = 0.5*(util.get_matrix_numpy(eb, 'prk8hr') +  util.get_matrix_numpy(eb, 'prk2hr'))\n",
    "    Park_cost = np.where(Park_cost>10, 10, Park_cost)\n",
    "    Park_cost = Park_cost.reshape(1, NoTAZ) + np.zeros((NoTAZ, 1))\n",
    "\n",
    "    sovcst = Park_cost\n",
    "    hovcst = Park_cost\n",
    "\n",
    "    ## Get Demands\n",
    "\n",
    "    sovdem = util.get_matrix_numpy(eb, \"NHbWSOVPerTrips\")\n",
    "    hovdem = util.get_matrix_numpy(eb, \"NHbWHOVPerTrips\")/Occ\n",
    "\n",
    "    # Calculate Costs\n",
    "\n",
    "    nhbwpark = ( sovcst*sovdem\n",
    "                        + hovcst*hovdem\n",
    "                        )\n",
    "\n",
    "    #######################\n",
    "    # NHBOther\n",
    "    #######################\n",
    "\n",
    "    Occ = float(util.get_matrix_numpy(eb, 'HOVOccNHBo'))\n",
    "    Park_cost = util.get_matrix_numpy(eb, 'prk2hr')\n",
    "    Park_cost = Park_cost.reshape(1, NoTAZ) + np.zeros((NoTAZ, 1))\n",
    "\n",
    "    hovcst = Park_cost\n",
    "\n",
    "    ## Get Demands\n",
    "\n",
    "    sovdem = util.get_matrix_numpy(eb, \"NHbOSOVPerTrips\")\n",
    "    hovdem = util.get_matrix_numpy(eb, \"NHbOHOVPerTrips\")/Occ\n",
    "\n",
    "    # Calculate Costs\n",
    "\n",
    "    nhbopark = ( hovcst*sovdem\n",
    "                        + hovcst*hovdem\n",
    "                        )\n",
    "\n",
    "    tot_parking = hbwpark.flatten() + hbupark.flatten() + hbshpark.flatten() + hbpbpark.flatten() + hbsopark.flatten() + nhbwpark.flatten() + nhbopark.flatten()\n",
    "    df['parking_paid'] = tot_parking\n",
    " \n",
    "    dfGy = df.groupby(['gy_i','gy_j'])\n",
    "    dfGy = dfGy.sum().reset_index()\n",
    "\n",
    "    conn = util.get_db_byname(eb, 'trip_summaries.db')\n",
    "    dfGy.to_sql(name='parkingPaid', con=conn, flavor='sqlite', index=False, if_exists='replace')   \n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "def ExecuteQry(eb, output_db, qry_file_name, measure_name=None, wide_to_long=False):\n",
    "    output_db_name = output_db\n",
    "    qry = qry_file_name\n",
    "    \n",
    "    proj_path = os.path.dirname(_m.Modeller().desktop.project.path)\n",
    "    file_path = os.path.join(proj_path, 'Scripts\\\\tl_internal_tools\\\\summary_sql','{}'.format(qry))\n",
    " \n",
    "    fd = open(file_path, 'r')\n",
    "    sqlCmd = fd.read()\n",
    "    fd.close()\n",
    "\n",
    "    conn = util.get_db_byname(eb, 'trip_summaries.db')\n",
    "    df = pd.read_sql(sqlCmd, conn)\n",
    "    conn.close()\n",
    "\n",
    "    if wide_to_long:\n",
    "        df = pd.melt(df, id_vars = ['scenario','alternative','horizon_year','peak'], var_name = 'mode', value_name = 'value')\n",
    "        df['measure'] = \"{}\".format(measure_name)\n",
    "        df = df[['scenario','alternative','horizon_year','peak','mode','measure','value']]\n",
    "    \n",
    "    try:\n",
    "        output_db = os.path.join(proj_path, output_db_name)\n",
    "        conn = sqlite3.connect(output_db)\n",
    "        df.to_sql(name='summary_metrics', con=conn, flavor='sqlite', index=False, if_exists='append')\n",
    "        conn.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Query {} addition to summary table failed.\".format(qry), e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update all runs in project (this section probably not needed anymore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "# THIS WILL BE DEPRECATED  with new model runs\n",
    "for eb in ebs:\n",
    "    title = eb.title()\n",
    "        \n",
    "    if title == 'Minimal Base Databank':\n",
    "        continue\n",
    "    \n",
    "    eb.open()\n",
    "    eb = _m.Modeller().emmebank\n",
    "    try:\n",
    "        data_export(eb)\n",
    "        autoStats(eb)\n",
    "        md = {'scenario' :'BusinessAsUsual',\n",
    "              'alternative' : title,\n",
    "              'horizon_year' : 2030}\n",
    "        md = pd.DataFrame(md, index=[0])\n",
    "        md['alternative'] = title\n",
    "        conn = util.get_rtm_db(eb)\n",
    "        md.to_sql(name='metadata', con=conn, flavor='sqlite', index=False, if_exists='replace')\n",
    "        conn.close()\n",
    "        conn = util.get_db_byname(eb, 'trip_summaries.db')\n",
    "        md.to_sql(name='metadata', con=conn, flavor='sqlite', index=False, if_exists='replace')\n",
    "        conn.close()      \n",
    "        ParamsTable(eb)\n",
    "        TransitRevenue(eb)\n",
    "        LosDTime(eb)          \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Scenario {} update failed.\".format(title), e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the dataprocessing functions on all of the dbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "# need to setup the loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "scrolled": true,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "for eb in ebs:\n",
    "    title = eb.title()\n",
    "        \n",
    "    if title == 'Minimal Base Databank':\n",
    "        continue\n",
    "    \n",
    "    eb.open()\n",
    "    eb = _m.Modeller().emmebank\n",
    "    try:    \n",
    "        # ParamsTable(eb) # bring this back once the other stuff is standard output\n",
    "        # TransitRevenue(eb)\n",
    "        # LosDTime(eb)\n",
    "        # CalcParking(eb)\n",
    "        ExecuteQry(eb, 'mp_t1_bl.db', 'aggNetResults.sql')\n",
    "        ExecuteQry(eb, 'mp_t1_bl.db', 'auto_tolls_by_mode_peak.sql')\n",
    "        ExecuteQry(eb, 'mp_t1_bl.db', 'auto_trips_by_mode_peak.sql')\n",
    "        ExecuteQry(eb, 'mp_t1_bl.db', 'avgTL_by_mode_peak.sql')\n",
    "        ExecuteQry(eb, 'mp_t1_bl.db', 'congested_vht_by_mode_peak.sql', 'congested_vht', wide_to_long=True)\n",
    "        ExecuteQry(eb, 'mp_t1_bl.db', 'congested_vkt_by_mode_peak.sql', 'congested_vkt', wide_to_long=True)\n",
    "        ExecuteQry(eb, 'mp_t1_bl.db', 'daily_mode_share.sql')\n",
    "        ExecuteQry(eb, 'mp_t1_bl.db', 'opcost_by_mode_peak.sql', 'opcost', wide_to_long=True)\n",
    "        ExecuteQry(eb, 'mp_t1_bl.db', 'revenue_transit_by_mode_peak.sql')\n",
    "        ExecuteQry(eb, 'mp_t1_bl.db', 'time_lost_by_mode_peak.sql', 'minutes_lost',wide_to_long=True)\n",
    "        ExecuteQry(eb, 'mp_t1_bl.db', 'transit_ridership_daily.sql')\n",
    "        ExecuteQry(eb, 'mp_t1_bl.db', 'transit_ridership_peak.sql')\n",
    "        ExecuteQry(eb, 'mp_t1_bl.db', 'vht_by_mode_peak.sql', 'vht', wide_to_long=True)\n",
    "        ExecuteQry(eb, 'mp_t1_bl.db', 'vkt_by_mode_peak.sql', 'vkt', wide_to_long=True)\n",
    "        # ExecuteQry(eb, 'mp_t1_bl.db', 'daily_parking_paid.sql')       \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Scenario {} update failed.\".format(title), e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "show_input": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add some additional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "proj_path = os.path.dirname(_m.Modeller().desktop.project.path)\n",
    "file_path = os.path.join(proj_path, 'Scripts\\\\tl_internal_tools\\\\expansion_factors.csv')\n",
    "\n",
    "dfe = pd.read_csv(file_path)\n",
    "output_db = os.path.join(proj_path, 'mp_t1_bl.db')\n",
    "conn = sqlite3.connect(output_db)\n",
    "dfe.to_sql(name='expansion_factors', con=conn, flavor='sqlite', index=False, if_exists='replace')\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "show_input": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for eb in ebs:\n",
    "    print counter, eb.title()\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "ebs[0].open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ],
    "collapsed": true,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "eb = _m.Modeller().emmebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "title = eb.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "print eb.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "conn = util.get_db_byname(eb, 'trip_summaries.db')\n",
    "df = pd.read_sql(\"SELECT * FROM netResults\", conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "proj_path = os.path.dirname(_m.Modeller().desktop.project.path)\n",
    "# file_path = os.path.join(proj_path, 'Scripts\\\\tl_internal_tools\\\\expansion_factors.csv')\n",
    "\n",
    "output_db = os.path.join(proj_path, 'mp_t1.db')\n",
    "conn = sqlite3.connect(output_db)\n",
    "df.to_sql(name='net_results_bl_2016', con=conn, flavor='sqlite', index=False, if_exists='replace')\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\" \n",
    "SELECT \n",
    "    e.i\n",
    "    ,e.j\n",
    "    ,e.peakperiod\n",
    "\n",
    "    ,e.speed as speed2016\n",
    "    ,f.speed as speed2045\n",
    "\n",
    "    ,e.losDspeed\n",
    "    ,CASE\n",
    "        WHEN (e.speed / e.losDspeed) < 0.85  THEN 1 ELSE 0 END cong_check_2016\n",
    "            \n",
    "    ,CASE \n",
    "        WHEN (f.speed / f.losDspeed) < 0.85  THEN 1 ELSE 0 END cong_check_2045   \n",
    "\n",
    "    ,CASE \n",
    "        WHEN (f.speed / f.losDspeed) < 0.85 and (e.speed / e.losDspeed) >= 0.85 THEN 1 ELSE 0 END new_future_congestion   \n",
    "\n",
    "\n",
    "  FROM net_results_bl_2016 e\n",
    "    LEFT JOIN net_results_bl_2045 f on f.i = e.i and f.j = e.j and f.peakperiod = e.peakperiod\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "proj_path = os.path.dirname(_m.Modeller().desktop.project.path)\n",
    "output_db = os.path.join(proj_path, 'mp_t1.db')\n",
    "\n",
    "conn = sqlite3.connect(output_db)\n",
    "df = pd.read_sql(sql, conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "show_input": true
   },
   "source": [
    "## Create Input Data for Heat Map Plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "util = _m.Modeller().tool(\"translink.util\")\n",
    "df = pd.concat([util.get_pd_ij_df(eb),util.get_ijensem_df(eb, 'gy','gy')], axis=1)\n",
    "\n",
    "df['amSovDemand1'] = util.get_matrix_numpy(eb, \"mfSOV_drvtrp_VOT_1_Am\").flatten()\n",
    "df['amSovDemand2'] = util.get_matrix_numpy(eb, \"mfSOV_drvtrp_VOT_2_Am\").flatten()\n",
    "df['amSovDemand3'] = util.get_matrix_numpy(eb, \"mfSOV_drvtrp_VOT_3_Am\").flatten()\n",
    "df['amSovDemand4'] = util.get_matrix_numpy(eb, \"mfSOV_drvtrp_VOT_4_Am\").flatten()\n",
    "\n",
    "df['mdSovDemand1'] = util.get_matrix_numpy(eb, \"mfSOV_drvtrp_VOT_1_Md\").flatten()\n",
    "df['mdSovDemand2'] = util.get_matrix_numpy(eb, \"mfSOV_drvtrp_VOT_2_Md\").flatten()\n",
    "df['mdSovDemand3'] = util.get_matrix_numpy(eb, \"mfSOV_drvtrp_VOT_3_Md\").flatten()\n",
    "df['mdSovDemand4'] = util.get_matrix_numpy(eb, \"mfSOV_drvtrp_VOT_4_Md\").flatten()\n",
    "\n",
    "df['pmSovDemand1'] = util.get_matrix_numpy(eb, \"mfSOV_drvtrp_VOT_1_Pm\").flatten()\n",
    "df['pmSovDemand2'] = util.get_matrix_numpy(eb, \"mfSOV_drvtrp_VOT_2_Pm\").flatten()\n",
    "df['pmSovDemand3'] = util.get_matrix_numpy(eb, \"mfSOV_drvtrp_VOT_3_Pm\").flatten()\n",
    "df['pmSovDemand4'] = util.get_matrix_numpy(eb, \"mfSOV_drvtrp_VOT_4_Pm\").flatten()\n",
    "\n",
    "\n",
    "df['amHovDemand1'] = util.get_matrix_numpy(eb, \"mfHOV_drvtrp_VOT_1_Am\").flatten()\n",
    "df['amHovDemand2'] = util.get_matrix_numpy(eb, \"mfHOV_drvtrp_VOT_2_Am\").flatten()\n",
    "df['amHovDemand3'] = util.get_matrix_numpy(eb, \"mfHOV_drvtrp_VOT_3_Am\").flatten()\n",
    "df['amHovDemand4'] = util.get_matrix_numpy(eb, \"mfHOV_drvtrp_VOT_4_Am\").flatten()\n",
    "\n",
    "df['mdHovDemand1'] = util.get_matrix_numpy(eb, \"mfHOV_drvtrp_VOT_1_Md\").flatten()\n",
    "df['mdHovDemand2'] = util.get_matrix_numpy(eb, \"mfHOV_drvtrp_VOT_2_Md\").flatten()\n",
    "df['mdHovDemand3'] = util.get_matrix_numpy(eb, \"mfHOV_drvtrp_VOT_3_Md\").flatten()\n",
    "df['mdHovDemand4'] = util.get_matrix_numpy(eb, \"mfHOV_drvtrp_VOT_4_Md\").flatten()\n",
    "\n",
    "df['pmHovDemand1'] = util.get_matrix_numpy(eb, \"mfHOV_drvtrp_VOT_1_Pm\").flatten()\n",
    "df['pmHovDemand2'] = util.get_matrix_numpy(eb, \"mfHOV_drvtrp_VOT_2_Pm\").flatten()\n",
    "df['pmHovDemand3'] = util.get_matrix_numpy(eb, \"mfHOV_drvtrp_VOT_3_Pm\").flatten()\n",
    "df['pmHovDemand4'] = util.get_matrix_numpy(eb, \"mfHOV_drvtrp_VOT_4_Pm\").flatten()\n",
    "\n",
    "df['amLGVDemand1'] = util.get_matrix_numpy(eb, \"mfLGVAM\").flatten()\n",
    "df['amHGVDemand1'] = util.get_matrix_numpy(eb, \"mfHGVAM\").flatten()\n",
    "df['mdLGVDemand1'] = util.get_matrix_numpy(eb, \"mfLGVMD\").flatten()\n",
    "df['mdHGVDemand1'] = util.get_matrix_numpy(eb, \"mfHGVMD\").flatten()\n",
    "df['pmLGVDemand1'] = util.get_matrix_numpy(eb, \"mfLGVPM\").flatten()\n",
    "df['pmHGVDemand1'] = util.get_matrix_numpy(eb, \"mfHGVPM\").flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "dfTime = pd.concat([util.get_pd_ij_df(eb),util.get_ijensem_df(eb, 'gy','gy')], axis=1)\n",
    "dfTime['amSovTime1'] = df['amSovDemand1'].multiply(util.get_matrix_numpy(eb, \"mfAmSovTimeVOT1\").flatten(), axis = 0)\n",
    "dfTime['amSovTime2'] = df['amSovDemand2'].multiply(util.get_matrix_numpy(eb, \"mfAmSovTimeVOT2\").flatten(), axis = 0)\n",
    "dfTime['amSovTime3'] = df['amSovDemand3'].multiply(util.get_matrix_numpy(eb, \"mfAmSovTimeVOT3\").flatten(), axis = 0)\n",
    "dfTime['amSovTime4'] = df['amSovDemand4'].multiply(util.get_matrix_numpy(eb, \"mfAmSovTimeVOT4\").flatten(), axis = 0)\n",
    "dfTime['mdSovTime1'] = df['mdSovDemand1'].multiply(util.get_matrix_numpy(eb, \"mfMdSovTimeVOT1\").flatten(), axis = 0)\n",
    "dfTime['mdSovTime2'] = df['mdSovDemand2'].multiply(util.get_matrix_numpy(eb, \"mfMdSovTimeVOT2\").flatten(), axis = 0)\n",
    "dfTime['mdSovTime3'] = df['mdSovDemand3'].multiply(util.get_matrix_numpy(eb, \"mfMdSovTimeVOT3\").flatten(), axis = 0)\n",
    "dfTime['mdSovTime4'] = df['mdSovDemand4'].multiply(util.get_matrix_numpy(eb, \"mfMdSovTimeVOT4\").flatten(), axis = 0)\n",
    "dfTime['pmSovTime1'] = df['pmSovDemand1'].multiply(util.get_matrix_numpy(eb, \"mfPmSovTimeVOT1\").flatten(), axis = 0)\n",
    "dfTime['pmSovTime2'] = df['pmSovDemand2'].multiply(util.get_matrix_numpy(eb, \"mfPmSovTimeVOT2\").flatten(), axis = 0)\n",
    "dfTime['pmSovTime3'] = df['pmSovDemand3'].multiply(util.get_matrix_numpy(eb, \"mfPmSovTimeVOT3\").flatten(), axis = 0)\n",
    "dfTime['pmSovTime4'] = df['pmSovDemand4'].multiply(util.get_matrix_numpy(eb, \"mfPmSovTimeVOT4\").flatten(), axis = 0)\n",
    "dfTime['amHovTime1'] = df['amHovDemand1'].multiply(util.get_matrix_numpy(eb, \"mfAmHovTimeVOT1\").flatten(), axis = 0)\n",
    "dfTime['amHovTime2'] = df['amHovDemand2'].multiply(util.get_matrix_numpy(eb, \"mfAmHovTimeVOT2\").flatten(), axis = 0)\n",
    "dfTime['amHovTime3'] = df['amHovDemand3'].multiply(util.get_matrix_numpy(eb, \"mfAmHovTimeVOT3\").flatten(), axis = 0)\n",
    "dfTime['amHovTime4'] = df['amHovDemand4'].multiply(util.get_matrix_numpy(eb, \"mfAmHovTimeVOT4\").flatten(), axis = 0)\n",
    "dfTime['mdHovTime1'] = df['mdHovDemand1'].multiply(util.get_matrix_numpy(eb, \"mfMdHovTimeVOT1\").flatten(), axis = 0)\n",
    "dfTime['mdHovTime2'] = df['mdHovDemand2'].multiply(util.get_matrix_numpy(eb, \"mfMdHovTimeVOT2\").flatten(), axis = 0)\n",
    "dfTime['mdHovTime3'] = df['mdHovDemand3'].multiply(util.get_matrix_numpy(eb, \"mfMdHovTimeVOT3\").flatten(), axis = 0)\n",
    "dfTime['mdHovTime4'] = df['mdHovDemand4'].multiply(util.get_matrix_numpy(eb, \"mfMdHovTimeVOT4\").flatten(), axis = 0)\n",
    "dfTime['pmHovTime1'] = df['pmHovDemand1'].multiply(util.get_matrix_numpy(eb, \"mfPmHovTimeVOT1\").flatten(), axis = 0)\n",
    "dfTime['pmHovTime2'] = df['pmHovDemand2'].multiply(util.get_matrix_numpy(eb, \"mfPmHovTimeVOT2\").flatten(), axis = 0)\n",
    "dfTime['pmHovTime3'] = df['pmHovDemand3'].multiply(util.get_matrix_numpy(eb, \"mfPmHovTimeVOT3\").flatten(), axis = 0)\n",
    "dfTime['pmHovTime4'] = df['pmHovDemand4'].multiply(util.get_matrix_numpy(eb, \"mfPmHovTimeVOT4\").flatten(), axis = 0)\n",
    "dfTime['amLGVTime1'] = df['amLGVDemand1'].multiply(util.get_matrix_numpy(eb, \"mfAmLgvTime\").flatten(), axis = 0)\n",
    "dfTime['amHGVTime1'] = df['amHGVDemand1'].multiply(util.get_matrix_numpy(eb, \"mfAmHgvTime\").flatten(), axis = 0)\n",
    "dfTime['mdLGVTime1'] = df['mdLGVDemand1'].multiply(util.get_matrix_numpy(eb, \"mfMdLgvTime\").flatten(), axis = 0)\n",
    "dfTime['mdHGVTime1'] = df['mdHGVDemand1'].multiply(util.get_matrix_numpy(eb, \"mfMdHgvTime\").flatten(), axis = 0)\n",
    "dfTime['pmLGVTime1'] = df['pmLGVDemand1'].multiply(util.get_matrix_numpy(eb, \"mfPmLgvTime\").flatten(), axis = 0)\n",
    "dfTime['pmHGVTime1'] = df['pmHGVDemand1'].multiply(util.get_matrix_numpy(eb, \"mfPmHgvTime\").flatten(), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "show_input": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "df = pd.melt(df, id_vars = ['i','j','gy_i','gy_j'], var_name = 'timeModeVot', value_name = 'trips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "dfTimeModeVot = df['timeModeVot'].str.extract(r'(?P<peak>[a|m|p]{1}[m|d])(?P<mode>Sov|Hov|LGV|HGV)Demand(?P<votclass>\\d)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "show_input": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([dfTimeModeVot, df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "del dfTimeModeVot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "dfTime = pd.melt(dfTime, id_vars = ['i','j','gy_i','gy_j'], var_name = 'timeModeVot', value_name = 'total_mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "df['total_mins'] = dfTime['total_mins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "del dfTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "df['scenario'] = 'mp_t1_hwy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "df['mode'] = np.where(df['mode'].isin(['Sov','Hov']), 'auto', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "df = df.groupby(['scenario','peak','mode','i', 'j', 'gy_i', 'gy_j'])\n",
    "df = df.sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "df = df[['scenario','peak', 'mode', 'i', 'j', 'gy_i', 'gy_j', 'trips', 'total_mins']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "show_input": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "proj_path = os.path.dirname(_m.Modeller().desktop.project.path)\n",
    "file_path = os.path.join(proj_path, 'hwy.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "show_input": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(file_path, sep = '\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
